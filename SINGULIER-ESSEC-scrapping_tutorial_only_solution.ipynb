{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPzN8dMqgZXK"
   },
   "source": [
    "# Web Scraping \n",
    "\n",
    "---\n",
    "\n",
    "### Singulier\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsibyhiq_btQ"
   },
   "source": [
    "Install the required package if it's not yet done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O81AYmZd_btR"
   },
   "outputs": [],
   "source": [
    "!pip3 install requests lxml pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9L9Vb5A_btS"
   },
   "source": [
    "# Import the needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3raWXfbt_btT"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "from pprint import pprint\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3ywOqxW_btb"
   },
   "outputs": [],
   "source": [
    "# Write the url you want to scrap\n",
    "url = \"https://www.trustpilot.com/review/tripmate.com\"\n",
    "\n",
    "# 'Request' the HTML of the page\n",
    "http_request = requests.get(url)\n",
    "\n",
    "# Retrieve its content\n",
    "page_content = http_request.content\n",
    "\n",
    "# Transform the HTML content to the right format\n",
    "page_html = html.fromstring(page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W41wuCNz_bte"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "  \"\"\"\n",
    "  Function to clean a text.\n",
    "  Takes a string and returns a string\n",
    "  \"\"\"\n",
    "  # join the list to have a string\n",
    "  cleaned_text = \"\".join(text)\n",
    "  # remove '\\n' and useless spaces\n",
    "  cleaned_text = cleaned_text.strip()\n",
    "  return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RhB-6hyF_btf"
   },
   "outputs": [],
   "source": [
    "def parse_review(review_block):\n",
    "  \"\"\"\n",
    "  Create a function to parse a review.\n",
    "  Takes an HTML element containing the review and returns a dictionnary with cleaned information\n",
    "  \"\"\"\n",
    "  # Create a dictionnary to store the results\n",
    "  info = dict()\n",
    "  # Write here the path to the title.\n",
    "  xpath_title = \".//h2//text()\"\n",
    "  # Retrieve the title\n",
    "  title = review_block.xpath(xpath_title)\n",
    "  # Clean the title\n",
    "  cleaned_title = clean_text(title)\n",
    "  # Store the title\n",
    "  info[\"title\"] = cleaned_title\n",
    "  # Same thing with the content\n",
    "  xpath_content = \".//p[@class='review-content__text']//text()\"\n",
    "  content = review_block.xpath(xpath_content)\n",
    "  cleaned_content = clean_text(content)\n",
    "  info[\"content\"] = cleaned_content\n",
    "  # Same thing with the rating\n",
    "  xpath_rating = \".//img/@alt\"\n",
    "  rating = review_block.xpath(xpath_rating)\n",
    "  cleaned_rating = clean_text(rating)\n",
    "  info[\"rating\"] = cleaned_rating\n",
    "  # Same thing with the date, don't forget to clean it\n",
    "  xpath_date = \".//script[@data-initial-state='review-dates']//text()\"\n",
    "  date = review_block.xpath(xpath_date)\n",
    "  cleaned_info_dates = clean_text(date)\n",
    "  date_index = cleaned_info_dates.find(\"publishedDate\")\n",
    "  date_start_index = date_index + 16\n",
    "  date_end_index = date_start_index + 10\n",
    "  cleaned_date = cleaned_info_dates[date_start_index:date_end_index]\n",
    "  info[\"date\"] = cleaned_date\n",
    "  return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_y4kyMtK_btg"
   },
   "outputs": [],
   "source": [
    "def parse_page(page_html):\n",
    "    # Write the xpath of the result blocks\n",
    "    xpath_results = \"//div[contains(@class, 'review-card')]\"\n",
    "    # Get all the reviews\n",
    "    all_results = page_html.xpath(xpath_results)\n",
    "    # Create a list to store the scrapped information\n",
    "    all_reviews_info = []\n",
    "    # Explore all reviews\n",
    "    for review in all_results:\n",
    "        # For each review, get the information of the review\n",
    "        review_info = parse_review(review)\n",
    "        # Store them in the list all_reviews_info\n",
    "        all_reviews_info.append(review_info)\n",
    "    return all_reviews_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hknwD4Rh_bth"
   },
   "outputs": [],
   "source": [
    "def get_next_link(url, page_html):\n",
    "    # Write here the path to the next page.\n",
    "    xpath_next_link = \"//a[@data-page-number='next-page']/@href\"\n",
    "    # Retrieve the link to the next page\n",
    "    res_next_link = page_html.xpath(xpath_next_link)\n",
    "    \n",
    "    # Check whether or not there is a link\n",
    "    if len(res_next_link) > 0: # (i.e if the list is not empty)\n",
    "        res_next_link_cleaned = clean_text(res_next_link) # Then clean the result\n",
    "        next_link = urljoin(url, res_next_link_cleaned) # Get the absolute link\n",
    "    else:\n",
    "        next_link = None\n",
    "    return next_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nmM3_9wg_bti"
   },
   "outputs": [],
   "source": [
    "def scrap_all_reviews(url):\n",
    "    # Initialize 'next_url' that will be modified\n",
    "    # It's better to not alter the url parameter\n",
    "    next_url = url\n",
    "    # Create a list to store the results\n",
    "    all_reviews = []\n",
    "    # Explore all the urls\n",
    "    while next_url is not None:\n",
    "        # 'Request' the HTML\n",
    "        http_request = requests.get(next_url)\n",
    "        # Retrieve its content\n",
    "        page_content = http_request.content\n",
    "        # Transform the HTML content to the right format\n",
    "        page_html = html.fromstring(page_content)\n",
    "        # Scrap the reviews of the page\n",
    "        page_reviews = parse_page(page_html)\n",
    "        # Store the scrapped reviews\n",
    "        all_reviews += page_reviews\n",
    "        # Display a message to show completion\n",
    "        print(f\"Done with {next_url}\")\n",
    "        # Get the url of the next page\n",
    "        next_url = get_next_link(next_url, page_html)\n",
    "    return all_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "epI8gTew_bti"
   },
   "outputs": [],
   "source": [
    "url = \"https://www.trustpilot.com/review/tripmate.com\"\n",
    "all_reviews = scrap_all_reviews(url)\n",
    "print(f\"Scrapped {len(all_reviews)} reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYDUu1YZ_bti"
   },
   "source": [
    "Check that the total number of reviews scrapped matches the total number of reviews mentionned on the website. If it's not the case, try to investigate why. For instance, go to the last page scrapped and see if there are other reviews available in other languages but not displayed etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8Mgz8tGQcFt"
   },
   "source": [
    "## Customer Reviews Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m_Tf24Dw_bti"
   },
   "outputs": [],
   "source": [
    "# Package to handle the date\n",
    "import pandas as pd\n",
    "\n",
    "#Packages to display graphs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(rc={'figure.figsize':(10, 5)})\n",
    "# In the general case, avoid putting imports in the middle of the code\n",
    "# All imports must be at the top of the file\n",
    "# However, this is a training file, so that's ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ROymJAja_bti"
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame (= basically a table)\n",
    "df = pd.DataFrame(all_reviews)\n",
    "# Display first 10 rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Omc5VS6elSLy"
   },
   "source": [
    "### Let's save our results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Mi2yWc7lRUd"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "# Authenticate to tell Google Drive that you are in fact the owner of this Drive\n",
    "drive.mount('drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dpqBtCyE_bti"
   },
   "outputs": [],
   "source": [
    "# Give the path to the file where you want the reviews to be stored.\n",
    "# The Folder should already exist, go create it if it's not the case.\n",
    "filepath = \"drive/My Drive/Training - Scraping/customer_reviews_TripMate.xlsx\"\n",
    "# Save results in that file\n",
    "df.to_excel(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqiLj6dtQg2X"
   },
   "source": [
    "### Let's see how many reviews per rating the company got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYEjKWgGUD4U"
   },
   "outputs": [],
   "source": [
    "df_rating = df.groupby(\"rating\")[\"content\"].count()\n",
    "df_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cKZVp80WUItO"
   },
   "outputs": [],
   "source": [
    "df_rating = df_rating.reset_index()\n",
    "df_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bjAHtzMD_btj"
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=\"rating\", y=\"content\", data=df_rating)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psWrG__ARIci"
   },
   "source": [
    "### Let's see how many reviews per month the company got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fBtfwvaaQoX_"
   },
   "outputs": [],
   "source": [
    "# First transform the date into a readable format\n",
    "\n",
    "def get_year_month(date):\n",
    "  \"\"\"\n",
    "  Function to get the year and the month from a date.\n",
    "  Takes a string and returns a string.\n",
    "  \"\"\"\n",
    "  return pd.to_datetime(date[:7]) # Get the first 7 characters (year and month) and transform it into a datetime object\n",
    "\n",
    "df[\"date_year_month\"] = df[\"date\"].apply(get_year_month)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gwCL2RHMRizT"
   },
   "outputs": [],
   "source": [
    "# Plot the number of reviews per month\n",
    "\n",
    "df_year_month = df.groupby(\"date_year_month\")[\"content\"].count().reset_index()\n",
    "sns.lineplot(x=\"date_year_month\", y=\"content\", data=df_year_month)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJLmbA8lV4YE"
   },
   "outputs": [],
   "source": [
    "df_year_month_rating = df.groupby([\"date_year_month\", \"rating\"])[\"content\"].count().reset_index()\n",
    "\n",
    "sns.lineplot(x=\"date_year_month\", y=\"content\", data=df_year_month_rating,\n",
    "             hue=\"rating\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yOJT5lhDZYH8"
   },
   "outputs": [],
   "source": [
    "start_date = pd.to_datetime(\"2020-01-01\")\n",
    "end_date = pd.to_datetime(\"2020-10-01\")\n",
    "\n",
    "def is_within_select_period(date):\n",
    "  return date >= start_date and date < end_date\n",
    "\n",
    "df_select_period = df_year_month_rating[df_year_month_rating[\"date_year_month\"].apply(is_within_select_period)]\n",
    "df_select_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tcS07xIsaBmH"
   },
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"date_year_month\", y=\"content\", data=df_select_period,\n",
    "             hue=\"rating\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_sQQ-yjjVy-K"
   },
   "outputs": [],
   "source": [
    "df_year_month_rating = df_select_period.set_index([\"date_year_month\", \"rating\"]).unstack(\n",
    "                                fill_value=0\n",
    "                            ).asfreq(\n",
    "                                'MS', fill_value=0\n",
    "                            ).stack().sort_index(level=0).reset_index()\n",
    "\n",
    "df_year_month_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FjgQAMl9SRq5"
   },
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"date_year_month\", y=\"content\", data=df_year_month_rating,\n",
    "            hue=\"rating\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pcNlaTqEWQu0"
   },
   "outputs": [],
   "source": [
    "# Package to create wordclouds\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Is1RcTlxa-HO"
   },
   "outputs": [],
   "source": [
    "all_text_reviews = \" \".join(df[\"content\"])\n",
    "\n",
    "wordcloud = WordCloud(width=400, height=600, background_color=\"white\").generate(all_text_reviews)\n",
    "\n",
    "plt.figure( figsize=(10,10) )\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "scrapping_tutorial_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
